\begin{conclusion}
\label{chap:conclusion}

In the present work the GraphSLAM algorithm was implemented for solving the SLAM problem in the 2D scenario. The g$^2$o framework provided to be a good tool for least square nonlinear optimization, and it includes kernels methods for robust estimation. The algorithm make some assumptions about the robot models, in particular, it assumes zero-mean white Gaussian noise, and the Markov condition. However GraphSLAM proved to be robust to outliers and non-Gaussian noise.

The GraphSLAM implementation is able to deal with known and unknown data association of the landmarks. The known data association case is a simple application of the g$^2$o framework with the right parameters. The unknown data association is a more complicated case, since there is no a straightforward way to deal with it. A method of maximum likelihood was developed using the uncertainly information that can be retrieved from g$^2$o to create a correspondence test. Then this test was applied iteratively to give a solution to the unknown correspondence. To speed up the algorithm several strategies were implemented: incremental optimization, pose skipping and distant test, all were able to decrease significantly the computational time.

The GraphSLAM algorithm was also designed to be fine tuned, with several parameters for the user to set. these parameters includes: the informations in the robot model, the number of iteration of the optimization algorithm, the kernel width, the number of inter full optimization, the threshold of the correspondence and distant test. 

The algorithm was tested with simulated and real data, for known and unknown landmark association. The algorithm performed satisfactorily, being able to correct the path in all the tested cases, and achieved a low error when the groundtruth was available. It was even able to work correctly in real data, where several assumption about the robot model and the data no longer hold. The correctness of the results were confirmed checking imposed condition on the data, and comparing with similar implementations. 

A parameter analysis is made for several test scenarios, from which is concluded that a thorough election of some parameters must be made for the algorithm to work correctly, while others parameters affect the convergence speed. The biggest drawbacks of the algorithm are computation time, that can take in the order of hours for large dataset, and the trial-and-error tuning of the parameters that has to be made if no prior information of the robot model is known. 

As future work it is suggested to improve the algorithm speed, for example, by constructing incrementally the graph to optimize in g$^2$o. Another unsolved issue in this work are the management of false positive. It is suggested to implement a policy to discard landmarks that are observed only a limited number of times, specially if it's not observed were it should be. The algorithm could also be extended to work in the 3 dimensional case. This extension shouldn't be difficult since g$^2$o already support nodes and edges of three variables. 

\end{conclusion}